{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9116907",
   "metadata": {},
   "source": [
    "# Twitter did not come back on my Academic research application.\n",
    "# So I proceeded to work with the Archive analysis from\n",
    "# https://archive.org/download/archiveteam-twitter-stream-2022-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6f897097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import warnings\n",
    "import gzip\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2ed42292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2667, 36)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function loads the json files one at a time and converts them into dataframe\n",
    "def convert_json_to_dataframe(json_file):\n",
    "    \"\"\"A simple function to convert json file to dataframe\"\"\"\n",
    "    data = []\n",
    "    with open(json_file, 'r') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                json_data = json.loads(line)\n",
    "                data.append(json_data)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON line: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "# twit_file = '20220901000000.json'\n",
    "# Keeping the json files outside my git repository , to reduce git size\n",
    "twit_file = \"/Users/ambrosedesmond/CCT_Projects/Ambrose_MSC_BD_ADA_CA2/Twitter_Archive_Data/20220901/20220901000000.json\"\n",
    "df = convert_json_to_dataframe(twit_file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2228ff30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_tweets(df, col , search_word):\n",
    "    filtered_tweets = df[df[col].apply(lambda x: search_word.lower() in x.lower().split())]\n",
    "    return filtered_tweets\n",
    "\n",
    "\n",
    "search_word = 'gas'\n",
    "col = 'text'\n",
    "fdf = filter_tweets(df, col , search_word)\n",
    "fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_json_from_directory(directory, output_file):\n",
    "    extracted_data = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.json.gz'):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            with gzip.open(file_path, 'rb') as file:\n",
    "                for line in file:\n",
    "                    try:\n",
    "                        json_data = json.loads(line)\n",
    "                        extracted_data.append(json_data)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error parsing JSON line in {file_name}: {e}\")\n",
    "    df = convert_json_to_dataframe(extracted_data)\n",
    "    \n",
    "        for data in extracted_data:\n",
    "            json.dump(data, output)\n",
    "            return combined_json\n",
    "\n",
    "# path to my zipped tweets\n",
    "directory = \"/Users/ambrosedesmond/CCT_Projects/Ambrose_MSC_BD_ADA_CA2/Twitter_Archive_Data/20220901\"\n",
    "# output_file = \"/Users/ambrosedesmond/CCT_Projects/Ambrose_MSC_BD_ADA_CA2/Twitter_Archive_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cd215217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line count is : 0\n"
     ]
    }
   ],
   "source": [
    "# This function converts json to dataframe but only for keywords\n",
    "def convert_json_to_dataframe(json_file, search_words):\n",
    "    \"\"\" Convert json to Dataframe selecting for given key words\"\"\"\n",
    "    data = []\n",
    "    line_count = 0\n",
    "    with open(json_file, 'r') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                json_data = json.loads(line)\n",
    "                tweet_col = json_data['text']\n",
    "                for word in search_words:\n",
    "                    if word in tweet_col:\n",
    "                        data.append(json_data)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON line: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(f\"line count is : {line_count}\")\n",
    "    return df\n",
    "# twit_file = '20220901000000.json'\n",
    "search_words = ['gas']\n",
    "twit_file = \"/Users/ambrosedesmond/CCT_Projects/Ambrose_MSC_BD_ADA_CA2/Twitter_Archive_Data/20220901/20220901000000.json\"\n",
    "pdf = convert_json_to_dataframe(twit_file, search_words)\n",
    "pdf.shape\n",
    "pdf.to_csv('BREXIT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "206fdd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>entities</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>lang</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>display_text_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Aug 31 23:59:55 +0000 2022</td>\n",
       "      <td>1565127274923528201</td>\n",
       "      <td>1565127274923528201</td>\n",
       "      <td>RT @rogeria_chagas: @BetoAraujooo @carlosgiann...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [{'text': 'RodrigoGarciaInjusto',...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>pt</td>\n",
       "      <td>1661990395657</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thu Sep 01 00:00:05 +0000 2022</td>\n",
       "      <td>1565127316879073285</td>\n",
       "      <td>1565127316879073285</td>\n",
       "      <td>RT @eumatue3O: Único reverse que eu queria é d...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>pt</td>\n",
       "      <td>1661990405660</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thu Sep 01 00:00:09 +0000 2022</td>\n",
       "      <td>1565127333652168706</td>\n",
       "      <td>1565127333652168706</td>\n",
       "      <td>RT @_biamendesv: tugas a falar brasileiro irri...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>pt</td>\n",
       "      <td>1661990409659</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thu Sep 01 00:00:14 +0000 2022</td>\n",
       "      <td>1565127354636292097</td>\n",
       "      <td>1565127354636292097</td>\n",
       "      <td>RT @AnahyDeVargas14: insanlar Bazen #bornova  ...</td>\n",
       "      <td>&lt;a href=\"http://itunes.apple.com/us/app/twitte...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [{'text': 'bornova', 'indices': [...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>tr</td>\n",
       "      <td>1661990414662</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thu Sep 01 00:00:44 +0000 2022</td>\n",
       "      <td>1565127480465391618</td>\n",
       "      <td>1565127480465391618</td>\n",
       "      <td>@simoneavila10 Linda foto: Micheque vigarista,...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.565125e+18</td>\n",
       "      <td>1565125409041268737</td>\n",
       "      <td>74308250.0</td>\n",
       "      <td>74308250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>pt</td>\n",
       "      <td>1661990444662</td>\n",
       "      <td>[15, 97]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "1  Wed Aug 31 23:59:55 +0000 2022  1565127274923528201  1565127274923528201   \n",
       "2  Thu Sep 01 00:00:05 +0000 2022  1565127316879073285  1565127316879073285   \n",
       "3  Thu Sep 01 00:00:09 +0000 2022  1565127333652168706  1565127333652168706   \n",
       "4  Thu Sep 01 00:00:14 +0000 2022  1565127354636292097  1565127354636292097   \n",
       "5  Thu Sep 01 00:00:44 +0000 2022  1565127480465391618  1565127480465391618   \n",
       "\n",
       "                                                text  \\\n",
       "1  RT @rogeria_chagas: @BetoAraujooo @carlosgiann...   \n",
       "2  RT @eumatue3O: Único reverse que eu queria é d...   \n",
       "3  RT @_biamendesv: tugas a falar brasileiro irri...   \n",
       "4  RT @AnahyDeVargas14: insanlar Bazen #bornova  ...   \n",
       "5  @simoneavila10 Linda foto: Micheque vigarista,...   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "1  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "4  <a href=\"http://itunes.apple.com/us/app/twitte...      False   \n",
       "5  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "\n",
       "   in_reply_to_status_id in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "1                    NaN                      None                  NaN   \n",
       "2                    NaN                      None                  NaN   \n",
       "3                    NaN                      None                  NaN   \n",
       "4                    NaN                      None                  NaN   \n",
       "5           1.565125e+18       1565125409041268737           74308250.0   \n",
       "\n",
       "  in_reply_to_user_id_str  ... reply_count retweet_count favorite_count  \\\n",
       "1                    None  ...           0             0              0   \n",
       "2                    None  ...           0             0              0   \n",
       "3                    None  ...           0             0              0   \n",
       "4                    None  ...           0             0              0   \n",
       "5                74308250  ...           0             0              0   \n",
       "\n",
       "                                            entities favorited retweeted  \\\n",
       "1  {'hashtags': [{'text': 'RodrigoGarciaInjusto',...     False     False   \n",
       "2  {'hashtags': [], 'urls': [], 'user_mentions': ...     False     False   \n",
       "3  {'hashtags': [], 'urls': [], 'user_mentions': ...     False     False   \n",
       "4  {'hashtags': [{'text': 'bornova', 'indices': [...     False     False   \n",
       "5  {'hashtags': [], 'urls': [], 'user_mentions': ...     False     False   \n",
       "\n",
       "  filter_level  lang   timestamp_ms display_text_range  \n",
       "1          low    pt  1661990395657                NaN  \n",
       "2          low    pt  1661990405660                NaN  \n",
       "3          low    pt  1661990409659                NaN  \n",
       "4          low    tr  1661990414662                NaN  \n",
       "5          low    pt  1661990444662           [15, 97]  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a6d5c565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 36)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOOVE\n",
    "def filter_tweets(df, col , search_word):\n",
    "    filtered_tweets = df[df[col].str.contains(search_word, case=False)]\n",
    "    return filtered_tweets\n",
    "\n",
    "\n",
    "search_word = 'gas'\n",
    "\n",
    "col = 'text'\n",
    "fdf = filter_tweets(df, col , search_word)\n",
    "fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aff1c1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_tweets(df, col , search_word):\n",
    "    filtered_tweets = df[df[col].apply(lambda x: search_word.lower() in x.lower().split())]\n",
    "    return filtered_tweets\n",
    "\n",
    "\n",
    "search_word = 'gas'\n",
    "\n",
    "col = 'text'\n",
    "fdf = filter_tweets(df, col , search_word)\n",
    "fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_json_from_directory(directory, output_file):\n",
    "    extracted_data = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.json.gz'):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            with gzip.open(file_path, 'rb') as file:\n",
    "                for line in file:\n",
    "                    try:\n",
    "                        json_data = json.loads(line)\n",
    "                        extracted_data.append(json_data)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error parsing JSON line in {file_name}: {e}\")\n",
    "    df = convert_json_to_dataframe(extracted_data)\n",
    "    \n",
    "        for data in extracted_data:\n",
    "            json.dump(data, output)\n",
    "            return combined_json\n",
    "\n",
    "# path to my zipped tweets\n",
    "directory = \"/Users/ambrosedesmond/CCT_Projects/Ambrose_MSC_BD_ADA_CA2/Twitter_Archive_Data/20220901\"\n",
    "# output_file = \"/Users/ambrosedesmond/CCT_Projects/Ambrose_MSC_BD_ADA_CA2/Twitter_Archive_Data\"\n",
    "\n",
    "combined_json = extract_json_from_directory(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba743bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search for exact phrase in DataFrame column   REMOVE\n",
    "search_word = 'sample text'\n",
    "search_column = 'Column1'\n",
    "\n",
    "search_results = df[df[col].apply(lambda x: search_word.lower() in x.lower().split())]\n",
    "\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2768bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtdf = fdf[['created_at','text']]\n",
    "gtdf.to_csv('json_and__seperate_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dfd47482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "321872f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wed Aug 31 23:59:53 +0000 2022</td>\n",
       "      <td>@SupportForMT @marktuan \"Manifesting and hopin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Wed Aug 31 23:59:54 +0000 2022</td>\n",
       "      <td>RT @cult_and_fraud: 国税庁を騙る詐欺メールに注意！\\n『発行元：国税庁』...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Wed Aug 31 23:59:54 +0000 2022</td>\n",
       "      <td>RT @jennobenno: Gerrymandering has kept Steve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Wed Aug 31 23:59:54 +0000 2022</td>\n",
       "      <td>I can’t believe I forgot man. I was literally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Wed Aug 31 23:59:54 +0000 2022</td>\n",
       "      <td>@Clevta -3.5 on fanduel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at  \\\n",
       "9   Wed Aug 31 23:59:53 +0000 2022   \n",
       "21  Wed Aug 31 23:59:54 +0000 2022   \n",
       "32  Wed Aug 31 23:59:54 +0000 2022   \n",
       "36  Wed Aug 31 23:59:54 +0000 2022   \n",
       "39  Wed Aug 31 23:59:54 +0000 2022   \n",
       "\n",
       "                                                 text  \n",
       "9   @SupportForMT @marktuan \"Manifesting and hopin...  \n",
       "21  RT @cult_and_fraud: 国税庁を騙る詐欺メールに注意！\\n『発行元：国税庁』...  \n",
       "32  RT @jennobenno: Gerrymandering has kept Steve ...  \n",
       "36  I can’t believe I forgot man. I was literally ...  \n",
       "39                            @Clevta -3.5 on fanduel  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b1343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
