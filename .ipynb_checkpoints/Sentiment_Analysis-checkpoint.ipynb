{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88bf6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # We can suppress the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbd8720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06383ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Russia_War_TWEETS.csv\")\n",
    "df = df.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0890154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ambrosedesmond/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27299dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regular expressions to remove all special charecters.\n",
    "df[\"tweets\"] = df['tweets'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0e5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regular expressions to remove all tabs and carrige returns that were imported in original csv\n",
    "df[\"tweets\"] = df['tweets'].str.replace(r'\\r\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c79326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically stop words like this, an, a, the, etc that do not affect the meaning of the tweet will be removed\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79b57bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2331008720</th>\n",
       "      <td>Gerashchenko_en Well if people want this war t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617608573227352069</th>\n",
       "      <td>kariona_grabi DevSlashNull_ Omg how uninformed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20562637</th>\n",
       "      <td>Russias economy isnt facing disaster anytime s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61085452</th>\n",
       "      <td>oulosP We dont involve in Ukraines war with Ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048878207481655296</th>\n",
       "      <td>_StoleYourTV_ the fact you made this shows how...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                tweets\n",
       "Unnamed: 0                                                            \n",
       "2331008720           Gerashchenko_en Well if people want this war t...\n",
       "1617608573227352069  kariona_grabi DevSlashNull_ Omg how uninformed...\n",
       "20562637             Russias economy isnt facing disaster anytime s...\n",
       "61085452             oulosP We dont involve in Ukraines war with Ru...\n",
       "1048878207481655296  _StoleYourTV_ the fact you made this shows how..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0945dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = df['tweets'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93452091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda counts the  number of stop words in each tweet\n",
    "df[\"stopwords\"]  = df[\"tweets\"].apply(lambda x : len([x for x in x.split() if x in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdea6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda counts the number of upper case words in tweet , indicate shouting , anger ect\n",
    "df[\"upper\"]  = df[\"tweets\"].apply(lambda x : len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c262b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = df['tweets'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Warning this cell can take up to 20 mins to complete ################### \n",
    "# corrects spellings and grammer based on context\n",
    "# use txtblob to correct the tweet spelling\n",
    "from textblob import TextBlob\n",
    "df['tweets_correct?']= df[\"tweets\"].apply(lambda x : str(TextBlob(x).correct()))\n",
    "# pattern matching is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043de30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='sentiment_1', ascending=False)\n",
    "df = df.sort_values(by='sentiment_2', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
